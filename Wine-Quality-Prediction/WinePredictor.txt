ğŸ· Wine Classification using K-Nearest Neighbors (KNN)
This project implements a K-Nearest Neighbors (KNN) classification model to predict the type of wine based on its chemical properties.
It includes data preprocessing, model tuning (finding best k), and visualization of accuracy scores for different k values.

ğŸ“‚ Project Structure

â”œâ”€â”€ WinePredictor.csv               # Input dataset
â”œâ”€â”€ wine_predictor.py               # Python script containing the code
â”œâ”€â”€ Accuracy vs K value.png         # Accuracy plot output
â”œâ”€â”€ README.md                       # Project documentation
ğŸ“Œ Features
Data Cleaning

Removes missing values with dropna()

Data Preprocessing

Separates features (x) and target (y)

Standardizes features using StandardScaler

Model Training & Evaluation

Tests KNN for k values from 1 to 20

Tracks and stores accuracy for each k

Finds the best k value that yields highest accuracy

Evaluates final model with accuracy score and confusion matrix

Visualization

Line plot showing Accuracy vs K values

Saved as Accuracy vs K value.png

ğŸ›  Requirements
Install the required Python libraries:

pip install pandas numpy matplotlib scikit-learn
ğŸš€ How to Run
Place the dataset WinePredictor.csv in the project directory.

Run the script:


python wine_predictor.py
The program will:

Clean and scale the dataset

Test multiple k values for KNN

Plot and save Accuracy vs K graph

Print the best k value, accuracy, and confusion matrix

ğŸ“Š Example Output
Console Output:

Best value of k is :  6
Final best accuracy is :  98.61
[[15  0  0]
 [ 0 13  1]
 [ 0  0 16]]
Generated Plot:

Accuracy vs K value.png â€“ Shows model accuracy for k = 1 to 20.

ğŸ“Œ Notes
Standardizing data is important for KNN since itâ€™s distance-based.

we can change random_state in train_test_split for different train/test splits.